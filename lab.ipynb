{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn.metrics._dist_metrics' has no attribute 'DistanceMetric32'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdata_loader\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_loaders\u001b[39;00m \u001b[39mimport\u001b[39;00m get_loader, MnistDataLoader\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/torch-project/data_loader/data_loaders.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdataset\u001b[39;00m \u001b[39mimport\u001b[39;00m SegmentationDataset\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader\n\u001b[1;32m      9\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mMnistDataLoader\u001b[39;00m(BaseDataLoader):\n",
      "File \u001b[0;32m~/workspace/torch-project/data_loader/dataset.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset\n\u001b[0;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39maugmentation\u001b[39;00m \u001b[39mimport\u001b[39;00m get_train_augmentation, get_valid_augmentation\n\u001b[1;32m     12\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mSegmentationDataset\u001b[39;00m(Dataset):\n\u001b[1;32m     13\u001b[0m     \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m    <dataset folder structure>\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m    data-\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39m    이미지들은 모두 png!\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39m    '''\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/torch-project/data_loader/augmentation.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39malbumentations\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mA\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39malbumentations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpytorch\u001b[39;00m \u001b[39mimport\u001b[39;00m ToTensorV2\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_train_augmentation\u001b[39m(ORI_IMAGE_SIZE, TARGET_IMAGE_SIZE):\n",
      "File \u001b[0;32m~/anaconda3/envs/medical/lib/python3.8/site-packages/albumentations/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m absolute_import\n\u001b[1;32m      3\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m1.3.0\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39maugmentations\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcomposition\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mserialization\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/medical/lib/python3.8/site-packages/albumentations/augmentations/__init__.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcrops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[39m# New transformations goes to individual files listed below\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdomain_adaptation\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdropout\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchannel_dropout\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdropout\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcoarse_dropout\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/medical/lib/python3.8/site-packages/albumentations/augmentations/domain_adaptation.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mqudida\u001b[39;00m \u001b[39mimport\u001b[39;00m DomainAdapter\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskimage\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexposure\u001b[39;00m \u001b[39mimport\u001b[39;00m match_histograms\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdecomposition\u001b[39;00m \u001b[39mimport\u001b[39;00m PCA\n",
      "File \u001b[0;32m~/anaconda3/envs/medical/lib/python3.8/site-packages/qudida/__init__.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdecomposition\u001b[39;00m \u001b[39mimport\u001b[39;00m PCA\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping_extensions\u001b[39;00m \u001b[39mimport\u001b[39;00m Protocol\n\u001b[1;32m     10\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mTransformerInterface\u001b[39;00m(Protocol):\n",
      "File \u001b[0;32m~/anaconda3/envs/medical/lib/python3.8/site-packages/sklearn/decomposition/__init__.py:15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_pca\u001b[39;00m \u001b[39mimport\u001b[39;00m PCA\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_incremental_pca\u001b[39;00m \u001b[39mimport\u001b[39;00m IncrementalPCA\n\u001b[0;32m---> 15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_kernel_pca\u001b[39;00m \u001b[39mimport\u001b[39;00m KernelPCA\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_sparse_pca\u001b[39;00m \u001b[39mimport\u001b[39;00m SparsePCA, MiniBatchSparsePCA\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_truncated_svd\u001b[39;00m \u001b[39mimport\u001b[39;00m TruncatedSVD\n",
      "File \u001b[0;32m~/anaconda3/envs/medical/lib/python3.8/site-packages/sklearn/decomposition/_kernel_pca.py:23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseEstimator, TransformerMixin, _ClassNamePrefixFeaturesOutMixin\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m KernelCenterer\n\u001b[0;32m---> 23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpairwise\u001b[39;00m \u001b[39mimport\u001b[39;00m pairwise_kernels\n\u001b[1;32m     26\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mKernelPCA\u001b[39;00m(_ClassNamePrefixFeaturesOutMixin, TransformerMixin, BaseEstimator):\n\u001b[1;32m     27\u001b[0m     \u001b[39m\"\"\"Kernel Principal component analysis (KPCA) [1]_.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \u001b[39m    Non-linear dimensionality reduction through the use of kernels (see\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[39m    (1797, 7)\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/medical/lib/python3.8/site-packages/sklearn/metrics/__init__.py:41\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_classification\u001b[39;00m \u001b[39mimport\u001b[39;00m multilabel_confusion_matrix\n\u001b[1;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_dist_metrics\u001b[39;00m \u001b[39mimport\u001b[39;00m DistanceMetric\n\u001b[0;32m---> 41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m cluster\n\u001b[1;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcluster\u001b[39;00m \u001b[39mimport\u001b[39;00m adjusted_mutual_info_score\n\u001b[1;32m     43\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcluster\u001b[39;00m \u001b[39mimport\u001b[39;00m adjusted_rand_score\n",
      "File \u001b[0;32m~/anaconda3/envs/medical/lib/python3.8/site-packages/sklearn/metrics/cluster/__init__.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_supervised\u001b[39;00m \u001b[39mimport\u001b[39;00m fowlkes_mallows_score\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_supervised\u001b[39;00m \u001b[39mimport\u001b[39;00m entropy\n\u001b[0;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_unsupervised\u001b[39;00m \u001b[39mimport\u001b[39;00m silhouette_samples\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_unsupervised\u001b[39;00m \u001b[39mimport\u001b[39;00m silhouette_score\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_unsupervised\u001b[39;00m \u001b[39mimport\u001b[39;00m calinski_harabasz_score\n",
      "File \u001b[0;32m~/anaconda3/envs/medical/lib/python3.8/site-packages/sklearn/metrics/cluster/_unsupervised.py:16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m check_X_y\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m _safe_indexing\n\u001b[0;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpairwise\u001b[39;00m \u001b[39mimport\u001b[39;00m pairwise_distances_chunked\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpairwise\u001b[39;00m \u001b[39mimport\u001b[39;00m pairwise_distances\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m LabelEncoder\n",
      "File \u001b[0;32m~/anaconda3/envs/medical/lib/python3.8/site-packages/sklearn/metrics/pairwise.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfixes\u001b[39;00m \u001b[39mimport\u001b[39;00m delayed\n\u001b[1;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfixes\u001b[39;00m \u001b[39mimport\u001b[39;00m sp_version, parse_version\n\u001b[0;32m---> 33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_pairwise_distances_reduction\u001b[39;00m \u001b[39mimport\u001b[39;00m PairwiseDistancesArgKmin\n\u001b[1;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_pairwise_fast\u001b[39;00m \u001b[39mimport\u001b[39;00m _chi2_kernel_fast, _sparse_manhattan\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m DataConversionWarning\n",
      "File \u001b[0;32m~/anaconda3/envs/medical/lib/python3.8/site-packages/sklearn/metrics/_pairwise_distances_reduction/__init__.py:89\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Pairwise Distances Reductions\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# =============================\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39m#    using Generalized Matrix Multiplication over `float64` data (see the\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[39m#    docstring of :class:`GEMMTermComputer64` for details).\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_dispatcher\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     90\u001b[0m     BaseDistancesReductionDispatcher,\n\u001b[1;32m     91\u001b[0m     ArgKmin,\n\u001b[1;32m     92\u001b[0m     RadiusNeighbors,\n\u001b[1;32m     93\u001b[0m     sqeuclidean_row_norms,\n\u001b[1;32m     94\u001b[0m )\n\u001b[1;32m     96\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[1;32m     97\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mBaseDistancesReductionDispatcher\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     98\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mArgKmin\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     99\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mRadiusNeighbors\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    100\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msqeuclidean_row_norms\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    101\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/envs/medical/lib/python3.8/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:11\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m \u001b[39mimport\u001b[39;00m isspmatrix_csr\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_dist_metrics\u001b[39;00m \u001b[39mimport\u001b[39;00m BOOL_METRICS, METRIC_MAPPING\n\u001b[0;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_base\u001b[39;00m \u001b[39mimport\u001b[39;00m _sqeuclidean_row_norms32, _sqeuclidean_row_norms64\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_argkmin\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     13\u001b[0m     ArgKmin64,\n\u001b[1;32m     14\u001b[0m     ArgKmin32,\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_radius_neighbors\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     17\u001b[0m     RadiusNeighbors64,\n\u001b[1;32m     18\u001b[0m     RadiusNeighbors32,\n\u001b[1;32m     19\u001b[0m )\n",
      "File \u001b[0;32msklearn/metrics/_pairwise_distances_reduction/_base.pyx:1\u001b[0m, in \u001b[0;36minit sklearn.metrics._pairwise_distances_reduction._base\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sklearn.metrics._dist_metrics' has no attribute 'DistanceMetric32'"
     ]
    }
   ],
   "source": [
    "from data_loader.data_loaders import get_loader, MnistDataLoader\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from model.model import *\n",
    "import torch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary as summary\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "from model import loss\n",
    "import model.model as module_model\n",
    "import model.loss as module_loss\n",
    "import model.metric as module_metric\n",
    "# import logger\n",
    "from trainer import Trainer\n",
    "from torch.optim import lr_scheduler\n",
    "from monai.losses import MaskedDiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import SwinUNETR, UNet, RegUNet, AttentionUnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hklee/workspace/torch-project/data/plant/images/train /home/hklee/workspace/torch-project/data/plant/masks/train\n",
      "/home/hklee/workspace/torch-project/data/plant/images/valid /home/hklee/workspace/torch-project/data/plant/masks/valid\n"
     ]
    }
   ],
   "source": [
    "train_data_loader = get_loader(os.getcwd()+'/data/plant', batch_size=10, mode='train') # binary dataset\n",
    "valid_data_loader = get_loader(os.getcwd()+'/data/plant', batch_size=10, mode='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 240, 240])\n",
      "torch.float32\n",
      "torch.Size([10, 240, 240])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "for img ,mask in train_data_loader:\n",
    "    print(img.shape)\n",
    "    print(img.dtype)\n",
    "    print(mask.shape)\n",
    "    print(mask.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.py -> BaseModel 상속으로 바꾸고 학습되는지 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AttentionUnet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# model = UNET2().to(device)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# summary(model, (3, 240, 240))\t\t  \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m model \u001b[39m=\u001b[39m AttentionUnet(\n\u001b[1;32m      4\u001b[0m     spatial_dims\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m,\n\u001b[1;32m      5\u001b[0m     in_channels\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,\n\u001b[1;32m      6\u001b[0m     out_channels\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m      7\u001b[0m     channels\u001b[39m=\u001b[39m[\u001b[39m64\u001b[39m,\u001b[39m128\u001b[39m,\u001b[39m256\u001b[39m,\u001b[39m512\u001b[39m],\n\u001b[1;32m      8\u001b[0m     strides\u001b[39m=\u001b[39m[\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m]\n\u001b[1;32m      9\u001b[0m )\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AttentionUnet' is not defined"
     ]
    }
   ],
   "source": [
    "# model = UNET2().to(device)\n",
    "# summary(model, (3, 240, 240))\t\t  \n",
    "model = AttentionUnet(\n",
    "    spatial_dims= 2,\n",
    "    in_channels=3,\n",
    "    out_channels=1,\n",
    "    channels=[64,128,256,512],\n",
    "    strides=[1,1,1]\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = module_model.AttU_Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = module_model.MonaiAttentionUnet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "EPOCHS = 10\n",
    "epoch_loss_values = list()\n",
    "# criterion = torch.nn.BCEWithLogitsLoss()\n",
    "criterion = getattr(module_loss, 'bce_logitloss')\n",
    "optimizer = optim.Adam(list(model.parameters()), 1e-5)\n",
    "val_interval = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:04<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 average loss: 0.7677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:02<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 average loss: 0.7412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:02<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13 average loss: 0.7125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:02<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14 average loss: 0.6743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:02<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15 average loss: 0.6348\n",
      "check interval!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:02<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16 average loss: 0.5997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:02<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17 average loss: 0.5759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:02<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18 average loss: 0.5463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:02<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19 average loss: 0.5308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:02<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20 average loss: 0.5179\n",
      "check interval!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:02<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21 average loss: 0.5021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:02<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22 average loss: 0.4920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:02<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23 average loss: 0.4789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:02<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24 average loss: 0.4706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:02<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25 average loss: 0.4601\n",
      "check interval!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:02<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26 average loss: 0.4561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:02<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27 average loss: 0.4543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:02<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28 average loss: 0.4436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:02<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29 average loss: 0.4431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:02<00:00,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 average loss: 0.4405\n",
      "check interval!\n",
      "finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS, EPOCHS+20):\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    model.train() # switch to train mode\n",
    "    for step, batch in enumerate(tqdm(train_data_loader)):\n",
    "        inputs, labels = batch\n",
    "        # inputs = inputs.type('torch.FloatTensor')\n",
    "        # labels = labels.type('torch.FloatTensor')\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.unsqueeze(1).to(device) \n",
    "\n",
    "        # forward + backward + optimizer 최적화\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels) # loss 계산\n",
    "        \n",
    "        optimizer.zero_grad() # gradient(변화도) 0으로 만들고\n",
    "        loss.backward() # 역전파\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)    \n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0 :\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            print('check interval!')\n",
    "        \n",
    "print(\"finished\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer\n",
    "```\n",
    "trainer init\n",
    "    def __init__(self, model, criterion, metric_ftns, optimizer, config, device,\n",
    "                 data_loader, valid_data_loader=None, lr_scheduler=None, len_epoch=None):\n",
    "        super().__init__(model, criterion, metric_ftns, optimizer, config)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "EPOCHS = 30\n",
    "epoch_loss_values = list()\n",
    "# criterion = torch.nn.BCEWithLogitsLoss()\n",
    "criterion = DiceLoss()\n",
    "optimizer = optim.Adam(list(model.parameters()), 1e-5)\n",
    "val_interval = 5\n",
    "metrics = [getattr(module_metric, 'dice')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build optimizer, learning rate scheduler. delete every lines containing lr_scheduler for disabling scheduler\n",
    "lr_scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch : 0.95**epoch)\n",
    "\n",
    "trainer = Trainer(model, criterion, metrics, optimizer,\n",
    "                    config=config,\n",
    "                    device=device,\n",
    "                    data_loader=train_data_loader,\n",
    "                    valid_data_loader=valid_data_loader,\n",
    "                    lr_scheduler=lr_scheduler)\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/plant/images/test ./data/plant/masks/test\n",
      "torch.Size([10, 3, 240, 240])\n"
     ]
    }
   ],
   "source": [
    "test_loader = get_loader('./data/plant', mode='test', batch_size=10)\n",
    "for i in test_loader:\n",
    "    print(i[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 240, 240])\n",
      "tensor([0.0000, 0.0039, 0.0078, 0.0118, 0.0157, 0.0196, 0.0235, 0.0275, 0.0314,\n",
      "        0.0353, 0.0392, 0.0431, 0.0471, 0.0510, 0.0549, 0.0588, 0.0627, 0.0667,\n",
      "        0.0706, 0.0745, 0.0784, 0.0824, 0.0863, 0.0902, 0.0941, 0.0980, 0.1020,\n",
      "        0.1059, 0.1098, 0.1137, 0.1176, 0.1216, 0.1255, 0.1294, 0.1333, 0.1373,\n",
      "        0.1412, 0.1451, 0.1490, 0.1529, 0.1569, 0.1608, 0.1647, 0.1686, 0.1725,\n",
      "        0.1765, 0.1804, 0.1843, 0.1882, 0.1922, 0.1961, 0.2000, 0.2039, 0.2078,\n",
      "        0.2118, 0.2157, 0.2196, 0.2235, 0.2275, 0.2314, 0.2353, 0.2392, 0.2431,\n",
      "        0.2471, 0.2510, 0.2549, 0.2588, 0.2627, 0.2667, 0.2706, 0.2745, 0.2784,\n",
      "        0.2824, 0.2863, 0.2902, 0.2941, 0.2980, 0.3020, 0.3059, 0.3098, 0.3137,\n",
      "        0.3176, 0.3216, 0.3255, 0.3294, 0.3333, 0.3373, 0.3412, 0.3451, 0.3490,\n",
      "        0.3529, 0.3569, 0.3608, 0.3647, 0.3686, 0.3725, 0.3765, 0.3804, 0.3843,\n",
      "        0.3882, 0.3922, 0.3961, 0.4000, 0.4039, 0.4078, 0.4118, 0.4157, 0.4196,\n",
      "        0.4235, 0.4275, 0.4314, 0.4353, 0.4392, 0.4431, 0.4471, 0.4510, 0.4549,\n",
      "        0.4588, 0.4627, 0.4667, 0.4706, 0.4745, 0.4784, 0.4824, 0.4863, 0.4902,\n",
      "        0.4941, 0.4980, 0.5020, 0.5059, 0.5098, 0.5137, 0.5176, 0.5216, 0.5255,\n",
      "        0.5294, 0.5333, 0.5373, 0.5412, 0.5451, 0.5490, 0.5529, 0.5569, 0.5608,\n",
      "        0.5647, 0.5686, 0.5725, 0.5765, 0.5804, 0.5843, 0.5882, 0.5922, 0.5961,\n",
      "        0.6000, 0.6039, 0.6078, 0.6118, 0.6157, 0.6196, 0.6235, 0.6275, 0.6314,\n",
      "        0.6353, 0.6392, 0.6431, 0.6471, 0.6510, 0.6549, 0.6588, 0.6627, 0.6667,\n",
      "        0.6706, 0.6745, 0.6784, 0.6824, 0.6863, 0.6902, 0.6941, 0.6980, 0.7020,\n",
      "        0.7059, 0.7098, 0.7137, 0.7176, 0.7216, 0.7255, 0.7294, 0.7333, 0.7373,\n",
      "        0.7412, 0.7451, 0.7490, 0.7529, 0.7569, 0.7608, 0.7647, 0.7686, 0.7725,\n",
      "        0.7765, 0.7804, 0.7843, 0.7882, 0.7922, 0.7961, 0.8000, 0.8039, 0.8078,\n",
      "        0.8118, 0.8157, 0.8196, 0.8235, 0.8275, 0.8314, 0.8353, 0.8392, 0.8431,\n",
      "        0.8471, 0.8510, 0.8549, 0.8588, 0.8627, 0.8667, 0.8706, 0.8745, 0.8784,\n",
      "        0.8824, 0.8863, 0.8902, 0.8941, 0.8980, 0.9020, 0.9059, 0.9098, 0.9137,\n",
      "        0.9176, 0.9216, 0.9255, 0.9294, 0.9333, 0.9373, 0.9412, 0.9451, 0.9490,\n",
      "        0.9529, 0.9569, 0.9608, 0.9647, 0.9686, 0.9725, 0.9765, 0.9804, 0.9843,\n",
      "        0.9882, 0.9922, 0.9961, 1.0000])\n",
      "torch.Size([10, 1, 240, 240])\n",
      "tensor([0.0000, 0.0039])\n"
     ]
    }
   ],
   "source": [
    "iter_ = iter(test_loader)\n",
    "img, mask = next(iter_)\n",
    "print(img.shape)\n",
    "print(torch.unique(img))\n",
    "print(mask.shape)\n",
    "print(torch.unique(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, mask in test_loader:\n",
    "    img = img.to(device)\n",
    "    # outputs = model(img)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = outputs.to('cpu')\n",
    "outputs = torch.sigmoid(outputs)\n",
    "outputs = (outputs > 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_outputs = outputs.to('cpu').detach().numpy()\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    result = outputs[i, :, :, :].squeeze()\n",
    "    plt.imshow(result, cmap='bone')\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'monai_unet_epoch30_loss(Dice).png'\n",
    "torchvision.utils.save_image(outputs, f'./saved/{file_name}', nrow=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.to('cpu')\n",
    "img = img.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    result = img[i, :, :, :].squeeze()\n",
    "    result = result.transpose(1,2,0)\n",
    "    plt.imshow(result, cmap='bone')\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = mask.to('cpu').detach().numpy()\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    result = mask[i, :, :].squeeze()\n",
    "    # result = result.transpose(1,2,0)\n",
    "    plt.imshow(result, cmap='bone')\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monai Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import SwinUNETR, UNet, RegUNet, AttentionUnet\n",
    "\n",
    "model = UNet(\n",
    "    spatial_dims= 2,\n",
    "    in_channels=3,\n",
    "    out_channels=1,\n",
    "    channels=[64,128,256,512],\n",
    "    strides=[1,1,1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SwinUNETR(\n",
    "        img_size=(96, 96, 96),\n",
    "        in_channels=3,\n",
    "        out_channels=4,\n",
    "        feature_size=48\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros(shape=(240,240))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor(a)\n",
    "t.shape\n",
    "t = torch.unsqueeze(t, 0)\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, (3, 240, 240))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn.metrics._dist_metrics' has no attribute 'DistanceMetric32'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdata_loader\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset\u001b[39;00m \u001b[39mimport\u001b[39;00m SegmentationDataset\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdata_loader\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_loaders\u001b[39;00m \u001b[39mimport\u001b[39;00m SegmentationLoader, get_loader\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/torch-project/data_loader/dataset.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset\n\u001b[0;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39maugmentation\u001b[39;00m \u001b[39mimport\u001b[39;00m get_train_augmentation, get_valid_augmentation\n\u001b[1;32m     12\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mSegmentationDataset\u001b[39;00m(Dataset):\n\u001b[1;32m     13\u001b[0m     \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m    <dataset folder structure>\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m    data-\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39m    이미지들은 모두 png!\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39m    '''\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/torch-project/data_loader/augmentation.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39malbumentations\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mA\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39malbumentations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpytorch\u001b[39;00m \u001b[39mimport\u001b[39;00m ToTensorV2\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_train_augmentation\u001b[39m(ORI_IMAGE_SIZE, TARGET_IMAGE_SIZE):\n",
      "File \u001b[0;32m~/anaconda3/envs/medical/lib/python3.8/site-packages/albumentations/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m absolute_import\n\u001b[1;32m      3\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m1.3.0\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39maugmentations\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcomposition\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mserialization\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/medical/lib/python3.8/site-packages/albumentations/augmentations/__init__.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcrops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[39m# New transformations goes to individual files listed below\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdomain_adaptation\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdropout\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchannel_dropout\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdropout\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcoarse_dropout\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/medical/lib/python3.8/site-packages/albumentations/augmentations/domain_adaptation.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mqudida\u001b[39;00m \u001b[39mimport\u001b[39;00m DomainAdapter\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskimage\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexposure\u001b[39;00m \u001b[39mimport\u001b[39;00m match_histograms\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdecomposition\u001b[39;00m \u001b[39mimport\u001b[39;00m PCA\n",
      "File \u001b[0;32m~/anaconda3/envs/medical/lib/python3.8/site-packages/qudida/__init__.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdecomposition\u001b[39;00m \u001b[39mimport\u001b[39;00m PCA\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping_extensions\u001b[39;00m \u001b[39mimport\u001b[39;00m Protocol\n\u001b[1;32m     10\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mTransformerInterface\u001b[39;00m(Protocol):\n",
      "File \u001b[0;32m~/anaconda3/envs/medical/lib/python3.8/site-packages/sklearn/decomposition/__init__.py:15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_pca\u001b[39;00m \u001b[39mimport\u001b[39;00m PCA\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_incremental_pca\u001b[39;00m \u001b[39mimport\u001b[39;00m IncrementalPCA\n\u001b[0;32m---> 15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_kernel_pca\u001b[39;00m \u001b[39mimport\u001b[39;00m KernelPCA\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_sparse_pca\u001b[39;00m \u001b[39mimport\u001b[39;00m SparsePCA, MiniBatchSparsePCA\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_truncated_svd\u001b[39;00m \u001b[39mimport\u001b[39;00m TruncatedSVD\n",
      "File \u001b[0;32m~/anaconda3/envs/medical/lib/python3.8/site-packages/sklearn/decomposition/_kernel_pca.py:23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseEstimator, TransformerMixin, _ClassNamePrefixFeaturesOutMixin\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m KernelCenterer\n\u001b[0;32m---> 23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpairwise\u001b[39;00m \u001b[39mimport\u001b[39;00m pairwise_kernels\n\u001b[1;32m     26\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mKernelPCA\u001b[39;00m(_ClassNamePrefixFeaturesOutMixin, TransformerMixin, BaseEstimator):\n\u001b[1;32m     27\u001b[0m     \u001b[39m\"\"\"Kernel Principal component analysis (KPCA) [1]_.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \u001b[39m    Non-linear dimensionality reduction through the use of kernels (see\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[39m    (1797, 7)\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/medical/lib/python3.8/site-packages/sklearn/metrics/__init__.py:41\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_classification\u001b[39;00m \u001b[39mimport\u001b[39;00m multilabel_confusion_matrix\n\u001b[1;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_dist_metrics\u001b[39;00m \u001b[39mimport\u001b[39;00m DistanceMetric\n\u001b[0;32m---> 41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m cluster\n\u001b[1;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcluster\u001b[39;00m \u001b[39mimport\u001b[39;00m adjusted_mutual_info_score\n\u001b[1;32m     43\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcluster\u001b[39;00m \u001b[39mimport\u001b[39;00m adjusted_rand_score\n",
      "File \u001b[0;32m~/anaconda3/envs/medical/lib/python3.8/site-packages/sklearn/metrics/cluster/__init__.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_supervised\u001b[39;00m \u001b[39mimport\u001b[39;00m fowlkes_mallows_score\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_supervised\u001b[39;00m \u001b[39mimport\u001b[39;00m entropy\n\u001b[0;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_unsupervised\u001b[39;00m \u001b[39mimport\u001b[39;00m silhouette_samples\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_unsupervised\u001b[39;00m \u001b[39mimport\u001b[39;00m silhouette_score\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_unsupervised\u001b[39;00m \u001b[39mimport\u001b[39;00m calinski_harabasz_score\n",
      "File \u001b[0;32m~/anaconda3/envs/medical/lib/python3.8/site-packages/sklearn/metrics/cluster/_unsupervised.py:16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m check_X_y\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m _safe_indexing\n\u001b[0;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpairwise\u001b[39;00m \u001b[39mimport\u001b[39;00m pairwise_distances_chunked\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpairwise\u001b[39;00m \u001b[39mimport\u001b[39;00m pairwise_distances\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m LabelEncoder\n",
      "File \u001b[0;32m~/anaconda3/envs/medical/lib/python3.8/site-packages/sklearn/metrics/pairwise.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfixes\u001b[39;00m \u001b[39mimport\u001b[39;00m delayed\n\u001b[1;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfixes\u001b[39;00m \u001b[39mimport\u001b[39;00m sp_version, parse_version\n\u001b[0;32m---> 33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_pairwise_distances_reduction\u001b[39;00m \u001b[39mimport\u001b[39;00m PairwiseDistancesArgKmin\n\u001b[1;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_pairwise_fast\u001b[39;00m \u001b[39mimport\u001b[39;00m _chi2_kernel_fast, _sparse_manhattan\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m DataConversionWarning\n",
      "File \u001b[0;32m~/anaconda3/envs/medical/lib/python3.8/site-packages/sklearn/metrics/_pairwise_distances_reduction/__init__.py:89\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Pairwise Distances Reductions\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# =============================\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39m#    using Generalized Matrix Multiplication over `float64` data (see the\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[39m#    docstring of :class:`GEMMTermComputer64` for details).\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_dispatcher\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     90\u001b[0m     BaseDistancesReductionDispatcher,\n\u001b[1;32m     91\u001b[0m     ArgKmin,\n\u001b[1;32m     92\u001b[0m     RadiusNeighbors,\n\u001b[1;32m     93\u001b[0m     sqeuclidean_row_norms,\n\u001b[1;32m     94\u001b[0m )\n\u001b[1;32m     96\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[1;32m     97\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mBaseDistancesReductionDispatcher\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     98\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mArgKmin\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     99\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mRadiusNeighbors\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    100\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msqeuclidean_row_norms\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    101\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/envs/medical/lib/python3.8/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:11\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m \u001b[39mimport\u001b[39;00m isspmatrix_csr\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_dist_metrics\u001b[39;00m \u001b[39mimport\u001b[39;00m BOOL_METRICS, METRIC_MAPPING\n\u001b[0;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_base\u001b[39;00m \u001b[39mimport\u001b[39;00m _sqeuclidean_row_norms32, _sqeuclidean_row_norms64\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_argkmin\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     13\u001b[0m     ArgKmin64,\n\u001b[1;32m     14\u001b[0m     ArgKmin32,\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_radius_neighbors\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     17\u001b[0m     RadiusNeighbors64,\n\u001b[1;32m     18\u001b[0m     RadiusNeighbors32,\n\u001b[1;32m     19\u001b[0m )\n",
      "File \u001b[0;32msklearn/metrics/_pairwise_distances_reduction/_base.pyx:1\u001b[0m, in \u001b[0;36minit sklearn.metrics._pairwise_distances_reduction._base\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sklearn.metrics._dist_metrics' has no attribute 'DistanceMetric32'"
     ]
    }
   ],
   "source": [
    "from data_loader.dataset import SegmentationDataset\n",
    "from data_loader.data_loaders import SegmentationLoader, get_loader\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SegmentationLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_loader \u001b[39m=\u001b[39m SegmentationLoader(data_dir \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./data\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      2\u001b[0m                                    batch_size \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m,\n\u001b[1;32m      3\u001b[0m                                    mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m                                    image_size\u001b[39m=\u001b[39m\u001b[39m240\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SegmentationLoader' is not defined"
     ]
    }
   ],
   "source": [
    "train_loader = SegmentationLoader(data_dir = './data',\n",
    "                                   batch_size = 10,\n",
    "                                   mode='train',\n",
    "                                   image_size=240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_ = iter(train_loader)\n",
    "data=  next(iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.float32\n",
      "torch.Size([10, 3, 240, 240])\n",
      "<class 'torch.Tensor'>\n",
      "torch.float32\n",
      "torch.Size([10, 1, 240, 240])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, mask = data\n",
    "print(type(image))\n",
    "print(image.dtype)\n",
    "print(image.shape)\n",
    "print(type(mask))\n",
    "print(mask.dtype)\n",
    "print(mask.shape)\n",
    "torch.unique(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fig, (ax1, ax2) \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m2\u001b[39m, \u001b[39m10\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[1;32m      3\u001b[0m     ax1[i]\u001b[39m.\u001b[39mimshow(image[i, :, :, :]\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m0\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 10)\n",
    "for i in range(10):\n",
    "    ax1[i].imshow(image[i, :, :, :].permute(1,2,0))\n",
    "    ax2[i].imshow(mask[i,0,:,:])\n",
    "    ax1[i].axis('off')\n",
    "    ax2[i].axis('off')\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader.augmentation import get_train_augmentation, get_valid_augmentation\n",
    "from PIL import Image\n",
    "\n",
    "class TestDataset(SegmentationDataset):\n",
    "    def __init__(self, data_path, mode='train', image_size=240):\n",
    "        super().__init__(data_path, mode, image_size)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.images[idx]\n",
    "        filename = image_path.split('/')[-1].replace('jpg', 'png')\n",
    "        mask_path = os.path.join(self.mask_path, filename)\n",
    "\n",
    "        image = np.array(Image.open(image_path).convert('RGB'), dtype=np.float32)\n",
    "        mask = np.array(Image.open(mask_path).convert('L'), dtype=np.float32)\n",
    "\n",
    "        # 전처리, augmentation\n",
    "        augmentation = self.aug(image=image, mask=mask)\n",
    "        image = augmentation['image'] / 255.0\n",
    "        mask = augmentation['mask']\n",
    "        mask[mask == 255.0] = 1.0   \n",
    "        mask = mask.unsqueeze(0)\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/images/val ./data/masks/val\n",
      "[0. 1. 2. 3.]\n",
      "torch.Size([3, 240, 240])\n",
      "torch.Size([1, 240, 240])\n"
     ]
    }
   ],
   "source": [
    "brain = TestDataset('./data', 'val', 240)\n",
    "img, mask = brain.__getitem__(5)\n",
    "print(img.shape)\n",
    "print(mask.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass sementic segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([4, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "cls_one = torch.tensor([[0,0,0], [0,1,0],[0,1,0]])\n",
    "print(cls_one.shape)\n",
    "cls_two = torch.tensor([[1,1,1], [0,0,0], [0,0,0]])\n",
    "print(cls_two.shape)\n",
    "cls_three = torch.tensor([[0,0,0], [1,0,0], [1,0,0]])\n",
    "print(cls_three.shape)\n",
    "cls_four = torch.tensor([[0,0,0], [0,0,1], [0,0,1]])\n",
    "print(cls_four.shape)\n",
    "sample_mask = torch.stack([cls_one, cls_two, cls_three, cls_four])\n",
    "print(sample_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1],\n",
       "        [2, 0, 3],\n",
       "        [2, 0, 3]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argmax_mask = torch.argmax(sample_mask, dim=0)\n",
    "argmax_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0],\n",
       "         [0, 1, 0],\n",
       "         [0, 1, 0]],\n",
       "\n",
       "        [[1, 1, 1],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [1, 0, 0],\n",
       "         [1, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.nn.functional.one_hot(argmax_mask)\n",
    "preprocessed_m = m.permute(2,0,1)\n",
    "print(preprocessed_m.shape)\n",
    "preprocessed_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medical",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "c45b1e5adc3ad908ce4421ea0a9cbac3faff5d7d48500187266ce4b08c805d08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
